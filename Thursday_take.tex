\documentclass[draft,12pt]{llncs}  % TODO: download template, What's the
                                     % actual space like?
\include{prelude}

\begin{document}
\maketitle
\input{abstract}

\section{A Requirement for Data}
\label{sec:intro}

\todo{I feel like I don't make a very good case for the feedback loop here.
  Would like to go over this with Tim.}

Business process design is a field with high real-world impact. With a strong
economic importance and the possibility of affecting the jobs and incomes of
real people, the \emph{design} of a business process has to be given serious
attention: work which is undertaken without care, or with inadequate tooling,
can have moral consequences. Equally, when undertaken properly, it can have a
positive effect economically and on the people it concerns.
\par

With this in mind, a standard experimental paradigm extends to the treatment of
business processes. Models are constructed; initial design decisions are
taken in this modelling process. Models then produce data, which is summarised
into metrics of performance: the model can be analyzed via these metrics, and
tweaks can be made until the design it represents is satisfactory.
\par

\begin{figure}[h]
  \centering
  \includegraphics[height=\textheight/3,draft=false]{simple_feedback_loop.pdf}
  \caption[Feedback loop design]{The feedback loop of models producing data, the
    analysis of which influences the model}
  \label{fig:simple_feedback_loop}
\end{figure}

This procedure is reliant on available data in a number of ways. First, the
initial model must be constructed from a given understanding of what the desired
process is composed of. In the case of modeling existing processes,
the initial model could be derived from empirical data sets. The model also
generates data, the quality of which are key to producing useful analyses. So
long as the original model is sound, produces sound data, and produces data from
which sound measurements might be performed, a feedback loop is constructed
which can continually find improvements to the model's design. \par

This feedback loop is useful in both industry and in science. Such a practice is
capable of testing tools produced in both contexts, by way of producing and
analyzing data and asserting that the model's output is what is expected. For
example, security analysis tools such as STS-Tool, presented
in~\cite{salnitri2015sts}. It can also be used to verify new techniques for
modeling and analysis: for example, the application of log sanitization
from~\cite{cheng2015process} to synthetic data for testing purposes.
\par

Crucially, in industry, feedback loops such as the one proposed in~\cref{fig:2} these can be employed to prevent
business process designs which function poorly from being deployed in a
real-world environment, by simulating anticipated changes and making
improvements to existing systems. Deploying new business processes is an
expensive endeavor, and poorly-performing changes further increase costs, by way
of both their performance and their need for rapid replacement.
\par

Importantly, it is necessary to \emph{generate} the data involved in this
procedure, due to two factors. Firstly, empirical data is difficult for one to
collect without direct access to a model's subject process, and secondly, when
this data \emph{is} collected, it is typically privately held in the
organization which collected it, as data collection consumes resources and the
data a company ultimately collects may not be suitable for public dissemination.
% \footnote{It can, for example, contain trade secrets.}
Therefore, work in \emph{synthesizing} realistic data may reduce the cost of
data acquisition. Where acquisition is not possible, it may make data
readily available, enabling a greater number of practitioners to make use of the
above technique. The need for this has been established in similar work
involving the synthesis of generated
data~\citep{accorsi2013secsy,pourmasoumi2015business,mitsyuk2017generating}.
\par


\section{Current Methods in Generating Data}
Data can be generated via simulation from a model, as business processes consist of
complex systems. Simulations must become as
accurate as possible for the data generated to be reflective of the real world,
yet this requires very realistic models.
\par

The concern of this article is the effect unexpected variation in behavior can
have on the data generated by simulation, and the presentation of methods to
better employ such phenomena as a component of the model, so as to improve the
quality of the data it produces.
\par

To emulate the effect of behavioral variance on the output of a business process
simulation, it is necessary to produce data which indicates that the behavior in
a model deviates from what is expected. This ought to be evident in the event
log produced from a business process.
\par

\subsection{Post-simulation insertion of variance}
\cite{accorsi2013secsy} detail several modifications which can be made to event
logs taken from simulated runs of business processes. Their modifications are
high-level, focusing on changing certain properties of an event log which can
impact security metrics of interest to a user of their tool. Examples of these 
might be the bypassing of authentication, or disregard for a requirement of
separation of duty. SecSY, the tool produced by the work, emulates the affect of
security policy breech by simulating a business process and applying these
alterations post-hoc, to represent the effect of behavioral variance.
\par

This approach satisfies the authors' goals of producing logs which represent the
violation of a security policy, but the narrow focus of the work has
consequences for its generality. The modifications developed for SecSY are
largely security-oriented and do not serve a general-purpose use case.
Behavioral variance as usually seen in business process execution, such as an
overconfident or distracted employee, would be complex to represent in such a
way.
\par

Further, the approach cannot take into account the impact of knock-on
effects from an initial change. For example, an under-confident employee might
decide to repeat an action, which can appear in an event log as a duplicated
step. The impact of this in the real world is dependent on the step duplicated:
some steps in the business process might delegate work to other employees, for
example. Should such a step be duplicated, a \emph{realistic} event log ought to
exhibit the traces of two delegated actions instead of a single delegated trace.
\par

In other words, the choice to alter one part of a workflow can have consequences
elsewhere; because post-simulation insertion of variance is concerned with only
the initial workflow variance, and the relationship of affected steps with
respect to other actors and the rest of the workflow is unclear from an event
log, it is not feasible to make \emph{realistic} adjustments to an event log
after simulation.
\par


\subsection{Pre-simulation insertion of variance}
An alternative approach is to make amendments to the model
representing variation in behavior before executing the simulation.
\par

\cite{pourmasoumi2015business} detail a tool which is capable of producing
business process variants by applying modifications to block-structured models
via process structure trees. Process structure trees are useful for representing
changes to processes, because block-structured processes, which they were
designed to represent, were devised with a mathematical rigor which aids in
defining transformation functions over them~\citep{li2010mining}. These can be composed together to
eventually represent significant changes to the original process.\par

This approach solves the problem of emulating knock-on effects in event logs, as
the simulation of the business process producing an event log must take the any
past effects of variance into account. Limiting the approach is a reliance on
process structure trees: real-world variance can be complex to model, and
representing changes to processes as low-level changes to mathematical
structures make them tine-consuming to produce. Moreover, real-world systems are
complex and their variance nuanced, making a low-level representation
ill-suited.
\par

Finally, a feature of real-world variance is that processes are not dynamic:
they evolve over time, and part of the variance of a process is that actor-level
and environmental aspects of the model can alter the structure of the business
process from one point in time to the next. While this can in theory be
represented by a very large business process model with all possible paths at
all points in time, at scale this will produce an intractably large model. More
importantly, the variance may non-deterministically affect what the model looks
like at a future point in time, and scenarios like these cannot be embedded in
the model before it is run. Accurate simulation of behavioral variance include
how the behaviors \emph{change}; ``realistic'' models should therefore be
dynamically self-modifying.
\par


\subsection{A new approach: just-in-time model variation}
Rather than constructing a new model containing the required variance, or
editing simulation output to represent the effect the variance might have had,
we propose that an approach better-suited to represent the effects of real-world
variance is to describe it as a process change which is applied
during the simulation of the original business process.
\par

Depending on the implementation of such a technique, it can represent variance
at a more high level than something dependent on process structure trees, while
retaining the benefits of pre-simulation insertion of variance: knock-on effects
from simulation are retained, yet high level descriptions of variance are
possible, and models remain tractably small, as model variation can be inserted
and removed as it is required. In addition, the approach offers dynamic
restructuring of business processes, matching what an actor in a real-world
business process observes and allowing for non-deterministic process definition.
\par

\section{A primer on Dynamic Fuzzing}
\label{sec:dynamic_fuzzing_explained}
To achieve just-in-time model variation, we suggest employing Dynamic Fuzzing.
Dynamic Fuzzing is an experimental technique in software engineering\todo{Tim
  suggested a better phrase than this. If neither of us remember, consider
  removing.} where programs are rewritten during execution. The aim of this
section is to give an overview of the technique; its strengths are explored in
\cref{sec:dynamic_fuzzing_benefits}.
\par

Achieving mid-execution transformation of processes can be achieved in various
ways. For example, actively developed tools~\citep{pdsf} change the source code
of a program while it executes. For the purposes of this explanation, a new
approach is proposed, intended to reflect paradigms popular in the modern
workflow modeling community. A reference tool for this is currently in
development~\citep{workflowgraphs}.

\subsection{Workflow representation}
Before building a conceptual framework for mid-execution alteration of a
process, we will first define our workflow meta-model\todo{I \emph{think} this
  is a correct use of ``meta-model''}.
\par

Let us represent a workflow as a directed graph $G=\{V, E\}$, with entry point
to the workflow defined as a starting node, $s \in{} V$, and a set of nodes to end
a graph traversal on, $E \in G$, where each node on the graph
represents an activity in the workflow of a business process. Edges on this
graph represent possible future actions after the completion of the edge's origin.
\par

Assuming some function which executes any associated business process for a
given node, called \texttt{execute\_process}, and another which selects the next
action to be executed in the workflow, called \texttt{select\_successor}, executing
a process in the graph can be achieved using the following procedure:
\par

\begin{figure}[H]
  \begin{algorithm}
    curr_node = s
    while curr_node $\notin{} E$:
        execute_process curr_node
        curr_node = ( select_successor curr_node )
  \end{algorithm}
\end{figure}
\todo{The following log example can probably be deleted for space, or just
  explained succinctly}

The conciseness of this approach assists in both simple\todo{word choice ok?}
implementation, and modification to suit the needs of a given model. For example,
a version of the procedure which produces an event log as output, assuming a
function called \texttt{log} which adds a process execution to an event log,
might be implemented as:

\begin{figure}[H]
  \begin{algorithm}
    curr_node = s
    while curr_node $\notin{} E$:
        execute_process curr_node
        log curr_node
        curr_node = ( select_successor curr_node )
  \end{algorithm}
\end{figure}
\subsection{Implementing Dynamic Fuzzing}
\label{subsec:example_implementation_details}
With a representation of a process such as this, dynamic fuzzing can be
implemented with ``fuzzers'', which define the transformation on the workflow as
a graph transformation. Informally, the type of a fuzzer is $fuzzer ::
workflow\_graph \rightarrow workflow\_graph$. Let us assume all fuzzers $f$ have
inverse functions which undo their effects, denoted $f_i$.
\par

Assume mappings \(v \in V, f(v)=F_v, i(v)=F_{v_i}\) where $f$ associates some
vertex on our graph $v$ with its associated set of fuzzers $F_v$, and a similar
mapping to collect the inverses of these fuzzers into a set of fuzzer inverses
mapped to the current node $F_{v_i}$. The graph transform takes and returns a
graph, meaning that the functions can be chained together, having equivalent
input and output types. We can therefore define a point-free function
$total\_fuzz~v = \circ\{f(v)\}$\footnote{$\circ\{f(v)\}$ is here used to
  represent the composition of all functions in the set $f(v)$.} of type
$total\_fuzz :: vertex \rightarrow workflow\_graph \rightarrow workflow\_graph$,
and a similarly defined function to apply any inversions of previous fuzzings,
$apply\_inverses$. This gives a trivial application of dynamic fuzzing:

\begin{figure}[H]
  \begin{algorithm}
    curr_node = s
    while curr_node $\notin{} E$:
        G = ( total_fuzz curr_node G )
        execute_process
        curr_node G = ( apply_inverses curr_node G )
        curr_node = ( select_successor curr_node )
  \end{algorithm}
\end{figure}
By applying inverses associated with the current node, previous fuzzings can be
reset at the point at which they are no longer required, such as when the
current node is no longer within the region of the graph the inverted fuzzer
should be applied to. Before and after every execution of a part of a business
process associated with a node, the graph representing the workflow $G$ is
replaced with an updated variant, with the appropriate modifications
representing real-world variance applied (or removed).
\par

\subsection{Existing implementations}
Working implementations of Dynamic Fuzzing which can be immediately used for
modeling purposes exist, using a different technique to that described in
\cref{subsec:example_implementation_details}. PyDySoFu~\citep{pdsf} is a tool
which dynamically alters Python source code via a tree
representation\footnote{Specifically, PyDySoFu dynamically alters the abstract
  syntax tree associated with Python code, using aspect orientation to decouple
  behavioral variance --- described as a graph transform --- from behavior
  specification --- described as a Python program simulating expected
  behavior.}. Where models are implemented as simulations in Python, PyDySoFu
provides a mechanism for just-in-time insertion of behavioral variance in a
model. However, the authors doubt that this method for modeling is likely to
become well-adopted by the workflow modeling community, hence the alternative
approach described here.
\par

High-level descriptions of a process, as object-oriented code, do however
indicate that high-level modeling techniques for just-in-time insertion of
behavioral variance is possible. This therefore may address both issues of
generality (arising from security-oriented work in the past) and simplicity
(arising from the low-level process tree approach).
\par

Use of PyDySoFu for dynamic fuzzing in
workflow modeling is described in~\cite{wallis2018modelling}.
\par

\section{Dynamic Fuzzing as a Modeling Paradigm}
\label{sec:dynamic_fuzzing_benefits}
The conceit of this section is that, properly employed, dynamically fuzzed
programs can express realistic models of business processes with variance.
Particularly, in this section we show that dynamic fuzzing can:

\begin{itemize}
\item Produce a realistic event log, complete with knock-on effects of
  behavioral variance
\item Support the construction of models simple enough to design and support
  tractably
\item Support the feedback loop mentioned in \cref{sec:intro}
\end{itemize}

\ldots{}the rationale for each point presented in their respective proceeding
subsections.

\subsection{Production of realistic event logs}
Use of dynamic fuzzing permits just-in-time insertion of behavioral variance in
a model, which provides the benefits of modeling knock-on effects and
dynamically altering the existence and impact of variance on the model.
\par

Inclusion of knock-on effects on the model, rather than inserting the immediate
effects of variance, overcomes the weaknesses identified in post-simulation
insertion of variance used in \cite{accorsi2013secsy}. This is a result of
knock-on effects from one stage of a simulation being taken into account in
later stages of the simulation as they can alter the state of the model
mid-execution.
\par

Meanwhile, dynamically altering the nature, impact, and existence of variance on
a model, mitigates the issues identified with the pre-simulation insertion of
variance identified in \cite{pourmasoumi2015business}. This is achieved by making its
manifestation dependent on the state of a simulation at execution time.
\par

As a result, the BPMDS paradigm dynamic fuzzing permits allows for models which
can be made more realistic than its pre-- and post-- insertion alternatives.
\par


\subsection{Tractably design-able and support-able models}
Models which can be designed and supported tractably should be small enough to
maintain, without sacrificing the complexity they may capture.
\par

Ideal behavior is specified by employing familiar workflow
modeling techniques. This ``blueprint'' of expected behavior is then enhanced
using separate descriptions of realistic variance separately to the original model. Model
size should be expected to grow slowly with the added complexity of variance in
this way: separation of concerns is a proven way to capture added complexity in
concise, yet expressive ways~\citep{kiczales1997aspect}.
\par

This technique has been successfully demonstrated in \cite{wallis2018modelling},
where software development methodologies were modeled and analyzed as an
evaluation of the approach for the development of tractably sized models.
Therefore, models can be expected to grow simply and maintain clarity by
employing the same rationale as well-studied software engineering practices.
\par

\subsection{Feedback loop support}
The feedback loop described in \cref{fig:simple_feedback_loop} relies on the
availability of data for rapid prototyping of a business process, and the design
and support of such a business process.
\par

Modeling improvements such as Dynamic Fuzzing permit more realistic data which
can be added to the aforementioned feedback loop, improving the overall efficacy
of standard design and engineering practices in BPMDS. Furthermore, the paradigm
dynamic fuzzing permits hints at an improved feedback loop for business process
design and support, where models are influenced by the analysis of the data they
produce \emph{as well as specification of properties such as variance}. 
\par

\begin{figure}[h]
  \centering
  \includegraphics[height=\textheight/3,draft=false]{variance_feedback_loop_simple.pdf}
  \caption[Feedback loop with variance]{A more sophisticated feedback loop,
    where varied behaviour improves the potential quality of analysis}
  \label{fig:complex_feedback_loop}
\end{figure}

As this feedback loop iteratevely improves not only the business process model,
but also the specification of its variance, this feature of the proposed
paradigm can be expected to enhance the realism of the model further via the
iterative improvement of both behavior and variance.
\par



\section{Next Steps}
\label{sec:future_work}
\label{sec:conclusion}
\subsection{Validating dynamic fuzzing for workflow modelling}
The proposed paradigm shows promise, but requires further experimental
validation.
\par

Some such validation can be found in \cite{wallis2018modelling}. A model
of software engineers working under different paradigms was developed so as to
model the impact of distraction on the workers' productivity, using Dynamic
Fuzzing via PyDySoFu's implementation via direct source code fuzzing. Further
case studies such as these, ideally verified against empirical data, is
necessary for a full validation of the technique via case study analysis.
\par

An alternative angle for validating the paradigm would be to generate realistic
event logs, and to evaluate them by identifying expected emergent properties in
the synthetic data. This approach is similar to the evaluation found
in~\cite{accorsi2013secsy} evaluation. Work toward employing this evaluation
technique is underway, where the BPI 2013 challenge model\todo{cite?} is being
rewritten using Dynamic Fuzzing, and emergent security vulnerabilities
identified via STS-Tool~\citep{salnitri2015sts}.
\par

Other approaches which could prove fruitful might involve the integration of the
paradigm into more typical workflow modeling practices. For example, executable
BPMN definitions~\citep{mitsyuk2017generating} may benefit for such an approach,
especially considering that data synthesis is a target use case for the work. In
addition, Petri nets are swiftly becoming the de facto implementation underlying
workflow modeling and process mining\citep{van1998application}, and an
implementation of Dynamic Fuzzing which operates over a petri net should be
feasible, given that petri nets are also graph representations of workflow
models.
\par

\subsection{Formal Methods}

\todo{TODO: write a little about possible automata work designing safe and
  formal rewrites of the graph. Plenty of sexy maths-y stuff we haven't done
  that somebody could. Temporal graphs etc.}

Integration of Dynamic Fuzzing into existing modeling paradigms such as petri
nets could permit future work which tackles a formal verification of a fuzzer's
``safety'': careless transformations on a graph might cause semantic
inconsistencies which could invalidate the model with respect to its
subject\todo{clumsy. Refactor this sentence? Maybe Tim knows a better way to
  phrase this!}. Semantic consistency and general fuzzer ``safety'' is an area
of research which requires much exploration.
\par

One way to approach safety would be to give fuzzing a strong formal foundation,
though work in automata theory. The advancement of the mathematical reasoning
found in~\cref{subsec:example_implementation_details} into something resembling
a Turing machine which rewrites itself before and after each transformation
would require formal limits on the transformation functions (and their
inverses)\footnote{The authors speculate that safety might be achieved by
  limiting the graph each transformation function applies to, making it only
  neighboring nodes. Should affects be required beyond this, part of the applied
  transformation can be the application of additional fuzzers, similarly to the
  application of additional inverses for the resetting of previous fuzzing
  activity. Work should also be done showing that these fuzzing functions
  \emph{can} have \emph{safe} inverses; if so, these functions appear to form a
  group. The mathematical implications of this seem to require lots of further
  study, and open many avenues to explore.}.
\par

\subsection{``Flow Fuzzing'' and ``Activity Fuzzing''}
Presented in~\cref{sec:dynamic_fuzzing_explained} is a method whereby a workflow
may be altered to represent the change in the actions an actor performs, with
regard the flow from one action to the next. Attention has not been paid here to
the manipulation of the \emph{effect} each action has on the state of a model.
\par

This detail can be modeled by PyDySoFu due to the general nature of its
implementation. Augmentation of the method presented
in~\cref{subsec:example_implementation_details} requires a well-developed
meta-model for the \emph{actions} represented in the workflow. To differentiate
between the two approaches, the authors propose the terms ``Flow Fuzzing'' and
``Activity Fuzzing'', for fuzzing the flow and the change of state during
workflow execution respectively. In addition, the authors would like to contrast
``Dynamic Fuzzing'' with ``Static Fuzzing'', the latter here considered the
application of a fuzzer only once, and not repeatedly throughout model
execution. An example of a ``Static Fuzzing'' technique is the pre-simulation
insertion of variance presented in~\cite{pourmasoumi2015business}. Dynamic
Action Fuzzing can be expected to provide increased realism in a model using
similar reasoning to that provided for Dynamic Action Fuzzing.
\par


\section{Closing}
The paradigm proposed represents a shift in what models are able to capture,
and, as a result, the strength of general BPMDS practices. The capture of
information within a model, as well as foundational\todo{sp?} improvements
to design and support practices, make just-in-time insertion of behavioral
variance via dynamic fuzzing a promising avenue of research for the BPMDS
community, in particular its growing cohort with interest in data synthesis.
\par

\section*{Acknowledgements}
The authors would like to thank OBASHI Technology for helping to fund this work.

\bibliography{lib}
\end{document}