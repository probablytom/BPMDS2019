\documentclass[12pt]{llncs}  % TODO: download template, What's the
                                     % actual space like?
\include{prelude}

\begin{document}
\maketitle
\input{abstract}

\section{A Requirement for Data}
\label{sec:intro}

% There's a feedback loop to design via modelling

% This feedback loop must be fed data!

% The feedback loop is really useful:
% - Used to test tools
% - Used to test models before deployment
% - Used in science for things like noise reduction on empirical datasets


% We need to generate it.
% - Data's hard to find
% - People are generating more and more sophisticated synthetic datasets
% implication: there's a need to generate realistic data.

Business process design is a field which, when treated properly, has an impact
on the world which can be difficult to overstate. With a strong economic
importance and the possibility of affecting the jobs and incomes of real people,
the \emph{design} of a business process has to be given serious attention: work
which is undertaken without care, or with inadequate tooling, can have moral
consequences. Equally, when undertaken properly, it can have a positive effect
economically and on the people it concerns.
\par

With this in mind, a standard experimental paradigm extends to the treatment of
business processes nicely. Models are constructed; initial design decisions are
taken in this modelling process. Models then produce data, which is summarised
into metrics of performance: the model can be analyses via these metrics, and
tweaks made until the design it represents is satisfactory.
\par

\todo{insert a figure representing this.}

This procedure is reliant on available data in a number of ways. The initial
model must be constructed from a given understanding of what the desired process
is composed of, for example. In the case of modeling existing processes, the
initial model could be derived from empirical data sets. The model also
generates data, the quality of which is key to producing useful analyses. So
long as the original model is sound, produces sound data, and produces data from
which sound measurements might be performed, a feedback loop is constructed
which can continually find improvements to the model's design.
\par

This feedback loop is useful in both industry and in science. Such a practice is
capable of testing tools produced in both contexts, by way of producing and
analyzing data and asserting via measurement that the model's output is what is
expected. It can also be used to verify new techniques for modeling and
analysis: an example might be the assessment of experimental techniques such as
log sanitization~\citep{cheng2015process}.
\par

\todo{I feel this is quite waffle-y. Cut some stuff here.}

Crucially, in industry, feedback loops such as these can be employed to prevent
business process designs which function poorly from being deployed in a
real-world environment, by simulating anticipated changes and making
improvements to existing systems. Deploying new business processes is an
expensive endeavor, and poorly-performing changes further increase costs, by way
of both their performance and their need for rapid replacement with something
workable.
\par

Importantly, it is necessary to \emph{generate} the data involved in this
procedure. This stems from two observations: firstly, empirical data is
difficult for one to collect without direct access to a model's subject process,
and secondly, when this data \emph{is} collected, it is typically silo-ed into
the organization which collected it, as the collection takes resources and the
data contained may not be suitable for public dissemination\footnote{It can, for
  example, contain trade secrets.}. Therefore, work in \emph{synthesizing}
realistic data may reduce the cost of data acquisition, and --- where acquisition is
not possible --- may make data readily available, enabling a greater number of
practitioners to make use of the above technique.
\par



\section{Current Methods in Generating Data}
Data can be generated via simulation from a model. Simulations must become as
accurate as possible for the data generated to be reflective of the real world,
yet this requires very realistic models. As business processes consist of
complex systems, producing a realistic model requires capturing nuanced data
about the subject process.
\par

The concern of this article is the effect unexpected variation in behaviour can
have on the data generated by simulation, and the presentation of methods to
better employ such phenomena as a component of the model so as to improve the
quality of the data it produces.
\par

To emulate the effect of behavioral variance on the output of a business process
simulation, it is necessary to produce data which indicates that the behavior in
a model deviates from what is expected. This ought to be evident in the an event
log produced from a business process, which is the focus of existing work on
business process variant generation.
\par

\subsection{Post-simulation insertion of variance}
\cite{accorsi2013secsy} detail several modifications which can be made to event
logs taken from simulated runs of business processes. Their modifications are
high-level, focusing on changing certain properties of an event log which can
impact security metrics of interest to a user of their tool. Examples of these 
might be the bypassing of authentication, or disregard for a requirement of
separation of duty. SecSY, the tool produced by the work, emulates the affect of
security policy breech by simulating a business process and applying these
alterations post-hoc, to represent the effect of behavioral variance.
\par

This approach satisfies the authors' goals of producing logs which represent the
violation of a security policy, but the narrow focus of the work has
consequences for its generality. For example, the modifications developed for
SecSY are largely security-oriented and do not serve a general-purpose use case.
Behavioural variance as usually seen in business process execution, such as an
overconfident or distracted employee, would be complex to represent in such a
way.
\par

More importantly, the approach --- inserting the effect of variance to a log
generated via a simulated run of a business process --- cannot take into account
the impact of knock-on effects from an initial lapse. For example, an
under-confident employee might decide to repeat an action, which can appear in
an event log as a duplicated step. The impact of this in the real world is
dependent on the step duplicated: some steps in the business process might
delegate work to other employees, for example. Should such a step be duplicated,
a \emph{realistic} event log ought to exhibit the traces of two delegated
actions instead of one.
\par

In other words, the choice to alter one part of a workflow can have consequences
elsewhere; because post-simulation insertion of variance is concerned with only
the initial workflow variance, and the relationship of affected steps with
respect to other actors and the rest of the workflow is unclear from an event
log, it is not possible to make \emph{realistic} adjustments to an event log
after simulation.
\par


\subsection{Pre-simulation insertion of variance}
If event logs cannot be altered to represent realistic variance after
simulation, an alternative approach could be to make amendments to the model
representing variation in behavior before executing the simulation.
\par

\cite{pourmasoumi2015business} detail a tool which is capable of producing
business process variants by applying modifications to block-structured models
via process structure trees. Process structure trees are useful for representing
changes to processes, because block-structured processes, which they were
designed to represent, were devised with a mathematical rigor which aids in
defining transformation functions over them~\citep{li2010mining}. These can be composed together to
eventually represent significant changes to the original process.\par

This approach solves the problem of emulating knock-on effects in event logs, as
the simulation of the business process producing an event log must take the
variance into account. Limiting the approach is a reliance on process structure
trees: real-world variance can be complex to model, and representing changes to
processes as low-level changes to mathematical structures make them
tine-consuming to produce. Moreover, real-world systems are complex and their
variance nuanced, making a low-level representation ill-suited.
\par

Finally, a feature of real-world variance is that processes are not dynamic:
they evolve over time, and part of the variance of a process is that actor-level
and environmental aspects of the model can alter the structure of the business
process from one moment to the next. While this can in theory be represented by
a very large business process model with all possible paths at all points in
time, at scale this should produce an intractably large model. More importantly,
the variance may non-deterministically determine what the model looks like at a
future point in time, and scenarios like these cannot be embedded in the model
before it is run.
\par


\subsection{A new approach: just-in-time model variation}
Rather than constructing a new model containing the required variance, or
editing simulation output to represent the effect the variance might have had,
we propose that an approach better-suited to represent the effects of real-world
variance is to describe such a variance as a process change which is applied
during the simulation of the original business process.
\par

Depending on the implementation of such a technique, it can be more high-level
than something dependent on process structure trees, while retaining the
benefits of pre-simulation insertion of variance: knock-on effects from
simulation are retained, high-level descriptions of variance are possible, and
models remain tractably small, as model variation can be inserted and removed as
it is required. In addition, the approach offers dynamic restructuring of
business processes, matching what a participant in a real-world business process
observes and allowing for non-deterministic process definition.
\par

\section{A primer on Dynamic Fuzzing}
\label{sec:dynamic_fuzzing_explained}
To achieve just-in-time model variation, we suggest employing Dynamic Fuzzing.
Dynamic Fuzzing is an experimental technique in software engineering\todo{Tim
  suggested a better phrase than this} where programs are rewritten during
execution. The aim of this section is to give an overview of the technique; its
strengths are explored in \cref{sec:dynamic_fuzzing_benefits}.
\par

Achieving mid-execution transformation of processes can be achieved in various
ways. For example, actively developed tools~\citep{pdsf} edit Python code during
execution by way of applying transformations to the program's abstract syntax
tree. For the purposes of this explanation, a new approach is proposed, intended
to reflect paradigms popular in the modern workflow modeling community. A
reference tool for this is currently in development~\citep{workflowgraphs}.

\subsection{Workflow representation}
Before building a conceptual framework for mid-execution alteration of a
process, we will first define our workflow meta-model\todo{I \emph{think} this
  is a correct use of ``meta-model''}.
\par

Let us represent a workflow as a directed graph $G=\{V, E\}$, with entry point
to the workflow defined as a starting node $s \in{} V$ where each node on the graph
represents an activity in the workflow of a business process. Edges on this
graph represent possible future actions after the completion of their
predecessor in the modeled business process.
\par

Assuming some function which executes any associated business process for a
given node, called \texttt{execute\_process}, and another which selects the next
action to be executed in the workflow, called \texttt{select\_successor}, executing
a process in the graph can be achieved using the following procedure:
\par

\begin{figure}[H]
  \begin{algorithm}
    curr_node = s
    while type of curr_node is not EndNode:
      execute_process curr_node
      curr_node = ( select_successor curr_node )
  \end{algorithm}
\end{figure}
\todo{The following log example can probably be deleted for space, or just
  explained succinctly}

The simplicity of this approach assists in both easy implementation and
modification to suit the needs of a given model. For example, a version of the
procedure which produces an event log as output, assuming a function which adds
a process to an event log called \texttt{log}, might be implemented as:

\begin{figure}[H]
  \begin{algorithm}
    curr_node = s
    while type of curr_node is not EndNode:
      execute_process curr_node
      log curr_node
      curr_node = ( select_successor curr_node )
  \end{algorithm}
\end{figure}
\subsection{Implementing Dynamic Fuzzing}
\label{subsec:example_implementation_details}
With a representation of a process such as this, dynamic fuzzing can be
implemented with ``fuzzers'', which define the transformation on the workflow
as a graph transformation. Informally, the type of a fuzzer is $fuzzer ::
workflow\_graph \rightarrow workflow\_graph$. Let us assume all fuzzers have inverse
functions which undo their effects, $f_i$.
\par

Assume mappings \(v \in V, f(v)=F_v, i(v)=F_{v_i}\) where $f$ associates some
vertex on our graph $v$ with its associated set of fuzzers $F_v$, and a similar
mapping to collect the inverses of these fuzzers into a set of fuzzer inverses
mapped to the current node $F_{v_i}$. The graph transform takes and returns a
graph, meaning that the functions can be chained together, having equivalent
input and output types. We can therefore define a point-free function
$total\_fuzz~v = map~f(v)$ of type $total\_fuzz :: vertex \rightarrow workflow
graph \rightarrow workflow\_graph$\footnote{The use of \texttt{map} here
  collects the set of fuzzers for $v$, $F_v$, and chains them together to be
  applied to some input workflow graph.}, and a similarly defined function to
apply any inversions of previous fuzzings, $apply\_inverses$. This gives a
trivial application of dynamic fuzzing:

\begin{figure}[H]
  \begin{algorithm}
    curr_node = s while type of curr_node is not EndNode: G = ( total_fuzz
    curr_node G ) execute_process curr_node G = ( apply_inverses curr_node G )
    curr_node = ( select_successor curr_node )
  \end{algorithm}
\end{figure}
By applying inverses associated with the current node, previous fuzzings can be
reset at the point at which they are no longer required, such as when the
current node is no longer within the region of the graph the given fuzzer should
be applied to. Before and every execution of a part of a business process
associated with a node, the graph representing the workflow $G$ is replaced with
an updated variant, with the appropriate modifications representing real-world
variance applied or removed.
\par

\subsection{Existing implementations}
Working implementations of Dynamic Fuzzing which can be immediately used for
modeling purposes exist, using a different technique to that described in
\cref{subsec:example_implementation_details}. PyDySoFu\citep{pdsf} is a tool
which dynamically alters Python source code via a tree
representation\footnote{Specifically, PyDySoFu dynamically alters the abstract
  syntax tree associated with Python code, using aspect orientation to decouple
  behavioral variance --- described as a graph transform --- from behaviour
  specification --- described as a Python program simulating expected
  behaviour}. Where models are implemented as simulations in Python, PyDySoFu
provides a mechanism for just-in-time insertion of behavioral variance in a
model. However, the authors doubt that this low-level implementation is not
immediately familiar to those in the workflow modeling community, hence the
alternative approach described here. Use of PyDySoFu for workflow modeling is
described in \cite{wallis2018modelling}.
\par

\section{Dynamic Fuzzing as a Modeling Paradigm}
\label{sec:dynamic_fuzzing_benefits}
The conceit of this section is that, properly employed, dynamically fuzzed
programs can express realistic models of business processes with variance.
Particularly, in this section we show that dynamic fuzzing can\ldots{}
\par

\begin{itemize}
\item Produce a realistic event log, complete with knock-on effects of
  behavioral variance
\item Support the construction of models simple enough to design and support
  tractably
\item Support the feedback loop mentioned in \cref{sec:intro}
\end{itemize}

\ldots{}the rationale for each point presented in their respective proceeding
subsections.

\subsection{Production of realistic event logs}
Use of dynamic fuzzing permits just-in-time insertion of behavioral variance in
a model, which provides the benefits of modeling knock-on effects and
dynamically altering the existence --- and impact --- of variance on the model.
\par

Inclusion of knock-on effects on the model, rather than inserting the immediate
effects of variance, overcomes the weaknesses identified in post-simulation
insertion of variance used in \cite{accorsi2013secsy}. Meanwhile, dynamically
altering the nature, impact and existence of variance on a model by making its
manifestation dependent on the state of a simulation mitigates the issues
identified with the pre-simulation insertion of variance identified in
\cite{pourmasoumi2015business}.
\par

As a result, the BPMDS paradigm dynamic fuzzing permits allows for models which
can be made more realistic than its pre-- and post-- insertion alternatives.
\par


\subsection{Tractably design-able and support-able models}
Models which can be designed and supported tractably should be small enough to
maintain, without sacrificing the complexity they may capture.
\par

Ideal behavior is specified using dynamic fuzzing by employing familiar workflow
modeling techniques. This ``blueprint'' of expected behavior is then enhanced
using descriptions of realistic variance separately to the original model. Model
size should be expected to grow slowly with the added complexity of variance in
this way: separation of concerns is a proven way to capture added complexity in
concise, yet expressive ways\citep{kiczales1997aspect}.
\par

This technique has been successfully demonstrated in \cite{wallis2018modelling},
where software development methodologies were modeled and analyzed as an
evaluation of the approach for the development of tractably sized models.
Therefore, models can be expected to grow simply and maintain clarity by
employing the same rationale as well-studied software engineering practices.
\par

\subsection{Feedback loop support}
The feedback loop described in \cref{sec:intro}\todo{Change to reference to a
  figure?} relies on the availability of data for rapid prototyping of a
business process, and the design and support of such a business process.
\par

Modeling improvements such as Dynamic Fuzzing permit more realistic data which
can be added to the aforementioned feedback loop, improving the overall efficacy
of standard design and engineering practices in BPMDS. Furthermore, the paradigm
dynamic fuzzing permits hints at an improved feedback loop for business process
design and support, where models are influenced by the analysis of the data they
produce \emph{as well as specification of properties such as variance}. 
\par

\todo{diagram here}

As this feedback loop iteratevely improves not only the business process model,
but the specification of its variance also, this feature of the proposed
paradigm can be expected to enhance the realism of the model further via the
iterative improvement of the new proposed components.
\par


% By following the procedure employed in
% \cref{subsec:example_implementation_details}, we achieve a graph-like fuzzing
% paradigm trivially compatible with literature on block-structured processes as
% defined in \cite{li2010mining}, as well as petri-net models and similar.

\section{Next Steps}
\label{sec:future_work}
\label{sec:conclusion}



\bibliography{lib}
\end{document}